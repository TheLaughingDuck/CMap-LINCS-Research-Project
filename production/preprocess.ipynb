{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arise, arise, Kernels of the Motherboard!\n"
     ]
    }
   ],
   "source": [
    "from utils import gctx, clean_doubling_time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "\n",
    "encourage = True\n",
    "if encourage: print(\"Arise, arise, Kernels of the Motherboard!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/data1/simjo484/cond_env/lib/python3.12/site-packages/cmapPy/pandasGEXpress/parse_gctx.py:275: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  meta_df = meta_df.apply(lambda x: pd.to_numeric(x, errors=\"ignore\"))\n",
      "/local/data1/simjo484/cond_env/lib/python3.12/site-packages/cmapPy/pandasGEXpress/parse_gctx.py:275: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  meta_df = meta_df.apply(lambda x: pd.to_numeric(x, errors=\"ignore\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first cell has been defeated! Kernel shall be shaken, Cooling fan be splintered,\n"
     ]
    }
   ],
   "source": [
    "# The gctx class simplifies processing of gctx files.\n",
    "# The warnings below are due to a deprecated use of error=\"false\" in the cmapPy package.\n",
    "# See https://github.com/cmap/cmapPy/blob/master/cmapPy/pandasGEXpress/parse_gctx.py\n",
    "data = gctx(\"/local/data1/simjo484/level5_beta_trt_cp_n720216x12328.gctx\")\n",
    "\n",
    "\n",
    "siginfo = pd.read_csv(\"/local/data1/simjo484/siginfo_beta.txt\", sep=\"\\t\", dtype=str)\n",
    "compoundinfo = pd.read_csv(\"/local/data1/simjo484/compoundinfo_beta.txt\", sep=\"\\t\", dtype=str)\n",
    "cellinfo = pd.read_csv(\"/local/data1/simjo484/cellinfo_beta.txt\", sep=\"\\t\", dtype=str)\n",
    "geneinfo = pd.read_csv(\"/local/data1/simjo484/geneinfo_beta.txt\", sep=\"\\t\", dtype=str)\n",
    "\n",
    "if encourage: print(\"The first cell has been defeated! Kernel shall be shaken, Cooling fan be splintered,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A second cell has fallen. Let the hope inspire you! Victory awaits!\n"
     ]
    }
   ],
   "source": [
    "# Create Dataframe with the unique signatures row-wise (and an index)\n",
    "# The index helps keep track of which rows are duplicated below, so that the labels also can be duplicated appropriately.\n",
    "X_raw = pd.DataFrame(data.cids, columns=[\"cids\"])\n",
    "X_raw[\"index\"] = [i for i in range(len(data.cids))]\n",
    "#print(X_raw.shape)\n",
    "\n",
    "# Join all the information we have on the unique signature\n",
    "X_raw = X_raw.merge(siginfo, how=\"left\", left_on=\"cids\", right_on=\"sig_id\")\n",
    "#print(X_raw.shape)\n",
    "\n",
    "# Join all the information we have on the pertubagens in general\n",
    "X_raw = X_raw.merge(compoundinfo, how=\"left\", left_on=\"pert_id\", right_on=\"pert_id\")\n",
    "#print(X_raw.shape)\n",
    "\n",
    "# Join cell information\n",
    "X_raw = X_raw.merge(cellinfo, how=\"left\", on=\"cell_iname\")\n",
    "#print(X_raw.shape)\n",
    "\n",
    "# Encode cell type\n",
    "X_raw = X_raw.join(pd.get_dummies(X_raw[\"cell_type\"], prefix=\"cell_type\"))\n",
    "#print(X_raw.shape)\n",
    "\n",
    "# Split up certain factor features\n",
    "#X_raw[\"cell_type_tumor\"] = X_raw[\"cell_type\"] == \"tumor\" # type are either \"normal\" or \"tumor\" or \"pool\"\n",
    "#X_raw.drop(\"cell_type\", axis=1)\n",
    "#X_raw = X_raw.join(pd.get_dummies(X_raw[\"cell_type\"], prefix=\"celltype\")) # celltype_normal and celltype_tumor\n",
    "\n",
    "if encourage: print(\"A second cell has fallen. Let the hope inspire you! Victory awaits!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another cell tumbles down before our Kernels, defeated! The admins smile upon us on this glorious day!\n"
     ]
    }
   ],
   "source": [
    "# Load the raw labels\n",
    "y_raw = data.obj.data_df.transpose()\n",
    "\n",
    "# Identify landmark genes\n",
    "landmark_gene_ids = geneinfo[geneinfo[\"feature_space\"] == \"landmark\"][\"gene_id\"].to_list()\n",
    "landmark_gene_ids = [str(i) for i in landmark_gene_ids]\n",
    "\n",
    "# Filter out non-landmark genes\n",
    "y_raw = y_raw[landmark_gene_ids]\n",
    "\n",
    "# duplicate as in X_raw\n",
    "y_raw = y_raw.iloc[X_raw[\"index\"],:]\n",
    "\n",
    "# Encode cell_lineage\n",
    "X_raw = X_raw.join(pd.get_dummies(X_raw[\"cell_lineage\"], prefix=\"cell_lineage\"))\n",
    "\n",
    "# Encode cell growth_pattern\n",
    "X_raw = X_raw.join(pd.get_dummies(X_raw[\"growth_pattern\"], prefix=\"growth_pattern\"))\n",
    "\n",
    "# Clean doubling_time\n",
    "#X_raw.loc[:,\"doubling_time\"] = [float(120) if val == \">120\" else float(val) for val in X_raw[\"doubling_time\"]]\n",
    "X_raw.loc[:, \"doubling_time\"] = [clean_doubling_time(i) for i in X_raw.loc[:,\"doubling_time\"]]\n",
    "#print(np.unique(X_raw.loc[:,\"doubling_time\"]))\n",
    "\n",
    "## THIS IS WHERE WE START THROWING AWAY ROWS AND COLUMNS ##\n",
    "X = X_raw.copy()\n",
    "y = y_raw.copy()\n",
    "\n",
    "if encourage: print(\"Another cell tumbles down before our Kernels, defeated! The admins smile upon us on this glorious day!\")\n",
    "#if ride == True: print(\"Cell shall be shaken, shield be splintered,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victory is within our grasp! Fight so that the algorithms back home may live yet another day!\n"
     ]
    }
   ],
   "source": [
    "# Remove observations with dose unit uM, because it does not play nice with the other does, and there are not many such observations\n",
    "#ind = (X[\"pert_dose_unit\"] != \"uM\") & (X[\"pert_dose_unit\"] != \"nan\") & (X[\"pert_dose_unit\"].isna() == False)\n",
    "#ind = ind.to_list()\n",
    "#X = X[ind]\n",
    "#y = y[ind]\n",
    "\n",
    "# Remove observations where dose unit is *not* micromolar (uM), because there are not many of them, and we want standardised data.\n",
    "ind = (X[\"pert_dose_unit\"] == \"uM\")\n",
    "ind = ind.to_list()\n",
    "X = X[ind]\n",
    "y = y[ind]\n",
    "\n",
    "# Convert dose to float (many are str, like \"0.6\").\n",
    "X.loc[:, \"pert_dose\"] = [float(i) for i in X[\"pert_dose\"]]\n",
    "\n",
    "# Standardise / normalise dose to the interval [0, 1]\n",
    "X.loc[:,\"pert_dose\"] = (X[\"pert_dose\"] - min(X[\"pert_dose\"])) / (max(X[\"pert_dose\"]) - min(X[\"pert_dose\"]))\n",
    "#X.loc[:,\"dose\"] = X[\"pert_dose\"]\n",
    "#X.drop(\"pert_dose\", axis=1)\n",
    "\n",
    "# Rename pert_dose\n",
    "X.loc[:,\"dose\"] = X.loc[:, \"pert_dose\"]\n",
    "#X.drop(\"pert_dose\", axis=1)\n",
    "\n",
    "if encourage: print(\"Victory is within our grasp! Fight so that the algorithms back home may live yet another day!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all doses to same unit (mg/ml) and then normalise\n",
    "#X.loc[:,\"pert_dose\"] = [standardize_dose_unit(dose, unit) for dose, unit in zip(X[\"pert_dose\"], X[\"pert_dose_unit\"])]\n",
    "#X.loc[:,\"pert_dose\"] = (X[\"pert_dose\"] - min(X[\"pert_dose\"])) / (max(X[\"pert_dose\"]) - min(X[\"pert_dose\"]))\n",
    "#X.loc[:,\"dose\"] = X[\"pert_dose\"]\n",
    "#X.drop(\"pert_dose\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onwards! Victory is on the horison!\n"
     ]
    }
   ],
   "source": [
    "# Just for a test, we remove all but a few arbitrary numerical features\n",
    "cell_lineage_columns = [\"cell_lineage_\" + i for i in [\"breast\", \"haematopoietic_and_lymphoid_tissue\", \"kidney\", \"large_intestine\", \"liver\", \"lung\", \"prostate\", \"skin\"]]\n",
    "growth_pattern_columns = [\"growth_pattern_\" + i for i in ['adherent', 'mix', 'suspension', 'unknown']]\n",
    "X = X[[\"dose\", \"pert_time\", \"cell_type_tumor\", \"cell_lineage_skin\", \"doubling_time\"] + cell_lineage_columns + growth_pattern_columns]\n",
    "\n",
    "if encourage: print(\"Onwards! Victory is on the horison!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All but one foul cell remains! Slay it!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1009496/492684487.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X = X.fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# Deal with Na's. Very naive at the moment.\n",
    "X = X.fillna(0)\n",
    "\n",
    "if encourage: print(\"All but one foul cell remains! Slay it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cells have fallen! Ride now, ride now! Ride to the next Notebook!\n"
     ]
    }
   ],
   "source": [
    "# Train, val, and test split\n",
    "X_train, X_intermed, y_train, y_intermed = train_test_split(X, y, train_size=0.7)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_intermed, y_intermed, train_size=0.5)\n",
    "\n",
    "if encourage: print(\"The cells have fallen! Ride now, ride now! Ride to the next Notebook!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### COMMENTS AND NOTES #########\n",
    "#sum(X_raw[\"pert_type\"] == \"trt_aby\") # remove \"trt_aby\"?\n",
    "\n",
    "######### COMMENTS AND NOTES #########\n",
    "\n",
    "\n",
    "# build_name is in siginfo_beta.txt, but I can't find any information on it i the netadatafiles.\n",
    "#keep_columns = [\"pert_dose\", \"pert_time\", \"pert_type\", \"cell_iname\", \"donor_age\", \"cell_lineage\"]\n",
    "#drop_columns = [\"cids\", \"bead_batch\", \"nearest_dose\", \"pert_dose_unit\", \"pert_idose\", \"pert_itime\", \"pert_time_unit\", \"cell_mfc_name\", \"pert_mfc_id\", \"nsample\", \"cc_q75\", \"ss_ngene\", \"tas\", \"wt\", \"median_recall_rank_spearman\", \"median_recall_rank_wtcs_50\", \"median_recall_score_spearman\", \"median_recall_score_wtcs_50\", \"batch_effect_tstat\", \"is_hiq\", \"qc_pass\", \"qc_pass\", \"det_wells\", \"det_plates\", \"distil_ids\", \"project_code\", \"pct_self_rank_q25\", \"batch_effect_tstat\", \"pert_id\", \"batch_effect_tstat_pct\", \"sig_id\", \"cell_iname\", \"build_name\", \"cmap_name_x\", \"is_exemplar_sig\", \"is_ncs_sig\", \"is_null_sig\", \"cmap_name_y\"]\n",
    "\n",
    "#drop_columns += [\"moa\", \"target\"] #These could be interesting, but there is some issue (moa: all nan, )\n",
    "\n",
    "#X_raw.drop(drop_columns + keep_columns, axis=1)\n",
    "\n",
    "#set(X[\"doubling_time\"])\n",
    "#[(float(val) if type(val) == str else float(val.removeprefix(\">\"))) for val in X[\"doubling_time\"]]\n",
    "\n",
    "#type(X[\"doubling_time\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
